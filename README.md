# test-repo
LG CNS ML Engineering Education

머신러닝 엔지니어링 (한재윤 책임)

수학과 - 머신러닝 석사 . 즉 분석가였다가 모델 코드를 깔끔하게 만들어보는게 어떨까?로 개발 입문

채용공고로 본인 분야의 trend를 파악하는 편임.


주요 프로젝트 - 공상평 HR 퇴직 예측 , L&D학습 추천 시스템 , U+ 아이들나라 추천시스템

머신러닝 모델 개발했던 분들 fancy하게 쓸 수 있음.

추천서 3개 - 사진 참고 (machine learning engineering - andriy burkov 번역본 있음, 2번째껀 사는거 추천 (제안서에 써먹을 그림 많음) , 3번째는 가장 많이 참고하는 책


M1. ML 엔지니어링 이해하기

ML 엔지니어링 왜 필요할까?

기존 ds업무는 전처리한 데이터 피처엔지니어링 하고 학습한 모델을 평가하여 공유하는 경우가 많음.
->분석가의 업무와 컨설턴트 업무가 섞여있는 경우가 많음.



고객수요 - ml 모델을 "운영시스템에 반영"하도록 요구하는 프로젝트가 많이 늘어나고 있음.


cns에서 ds에게 다양한 스킬이 필요해지고있음.
se는 데이터분석 프로세스 이해가 부족한반면 ds는 sw개발 프로세스중 중요한 요소(단위/통합테스트, git용어, erd,db용어 ci/cd)를 모르는 경우가 많다.
ds는 내 전문 영역은 이거니까 이거만 하면 된다 생각하는 경우가 많다.
ds는 데이터 요청하고 줄떄까지 기다리고 있는 경우가 많은데 시스템과 이행체계 전반을 몰라서 그런 경우가 많다.

이전 분석 PoC만 할때는 알고리즘 만드는 것에 집중하면 됐는데 요즘은 개발한 모델이 시스템에서 잘 운영될 수 있도록 하는 요구가 많아진다.

장상무님) 통계(데이터분석) 잘하는 인원은 많다. 하지만 데이터분석과 엔지니어링을 둘다 잘하는 사람은 없어서 고미니다. 둘 다 잘하는 사람을 육성하고 이런 역량 가진 사람 더 뽑고자 한다.

아직 담당내 ds보면 기존의 통계 기반 데이터 분석에 관심이 많은게 사실이다. 엔지니어링까찌 더불어 잘하는ㅅ ㅏ람 ㅁ낳지 않다. 둘다 하자.

고객은 ml모델 운영시스템에 반영
cns는 sw개발 용어와 mlops에 대한 이해를 바라고
ds조직은 엔지니어링도 잘하는 인력을 필요로 하고..

기존 데이터분석 영역에서 devops와 software engineering 까지 추가되고있는 와중임.

ML + Devops = Mlops

ML + SE = ML Engineering..


엔지니어에게 중요한것과 분석가에게 중요한 것을 합쳐보자.

그래서 무엇을 해야할까? -> 사진 참고 (엔지니어에게 중요한 것 & 분석가에게 중요한것)



바뀌어가는 일하는 방식 -사진참고(일하는 방식의 변화)


예시1)lg전자 sell-out 수요 예측 - 사진참고
예시2)lg cns L&D 학습 추천

ML 엔지니어 정의
- 데이터 수집부터 학습 배포 모델 유지보수 까지 머신러닝 사이클 전체를 보는 사람.

-사진 참고

MLE 업무 도구
ds와 비교해서 개발 표준, 개발도구(IDE), 자동화도구 를 많이 필요함. (git, mlflow 등)

MLE핵심
:ML모델은 ML 파이프라인의 작은 구성 요소일뿐
목표인 ML모델의 배포와 유지보수는 결국 ML을 둘러싼 요소들을 ML 파이프라인으로 얼마나 잘 생성했는지임

----------------------------------------------------
M2

ML시스템 운영시 가장 많은 업무? 트러블슈팅
-> clean code & git (효율적 혀법과 빠른 트러블 슈팅 위해)


2.1 clean code 중요성
:변수명 함수명 이해 안가
함수 어떻게 작동하는지 몰라
코드 줄바꿈 이상하거나 너무 길어
오류 발생 위치를 특정 짓기 어려움
코드에 담긴 비지니스 로직을 이해하기 어려움
누가 이 코드를 수정했는지 추적하기 어려움 (프로젝트 3명중 누가?)

clean code?
모든 팀원이 이해하기 쉽도로 작성한 코드다. 원저자가 아닌 다른 개발자가 읽고 개선할 수 있다.

규칙 4가지
1)follow standard convention 코드 표준과 기본 설계 가이드를 준수할것
2)KISS(Keep It Simple, Stupid) 단순할 수록 좋다. 복잡한 코드를 최대한 줄일 것
3)Boy Scout Rule 코드를 수정했다면 처음봤을때보다 더 깔끔하게 만들 것
4)Always find root cause 항상 근본적인 문제를 찾을 것. 그렇지 않으면 같은 문제가 반복됨.


파이썬은 코드 컨벤션 있음 -PEP8(파이썬으로 코드 작성할 때) (사진참고 page8)

1)명명법 -사진참고(page9)
2)코드 레이아웃 - 코드의 모든줄은 80글자 넘지 않는다. (다른 코드 옆에 놓았을때 기존 코드 줄바꿈 안되게)
  최상위 레벨의 함수나 클래스 사이는 두 줄을 띄운다. 
  클래스 내 서로 다른 메소드는 한 줄을 띄운다
  함수 안에서 공백줄을 최소화해 단계를 명확히 (길고 복잡한 함수는 각 단계를 명시하기 위해 공백 줄 필요시 추가)
  인라인 주석은 권장하지 않으며 일반 블록 주석을 권장함
  Docstring - 함수에 대한 설명 """ 으로 사이에 넣어주는 것 args랑 return이 뭐다 명시하려고 (구글 스타일, 넘파이스타일 등 있음)
  작은따옴표 큰따움표 모두 같은역할이니까 둘 중 하나만 사용한다. 
  이항 연산자 앞 뒤로 반드시 공배를 추가한다 - 사진참고 (page 17)
  임포트순서)
  스탠다드,서드파티,로컬 라이브러리 순서 지켜야함 기본적 알파벳 순서


PEP 484 - 타입 힌팅 type hinting
파이썬의 유연함의 단점으로 다른사람이 작성한 함수의 인자와 결과의 타입을 한눈에 보기 어려움
-> 함수 작성시 매개변수에 (x:str, y:str) -> str) 이런식으로 해주기

2.2 code convention
code convention 자동화
코드 컨벤션을 체크해주는 도구가 있음  
정적 분석 도구: 소스 코드 실행 없이 정적으로 프로그램의 문제 찾는 과정.
black , isort, mypy를 함께 쓰는 것을 추천함.
black : 널리 쓰이는 python 포맷터 , 설치시 주피터 노트북 호환되게 설치하면 사용 가능(pip install "black[jupyter]" 하면 됨)
isort : 임포트 순서 체크해줌


2.3 정적 분석 도구
나중에 공유해주실 파일에 clean code 적용 어떻게 됐는지 실습파일 주피터랑 비교해보기.
(변수 타입힌팅 등등)

2.4 git
이전까지는 실제 최종 버전이 언제 어떻게 변했는지 추적하기 어려워..
깃을토한 코드 히스토리 관리 및 여러 코드 작성자가 효과적으로 협업할 수 있는 코드 관리 기능있음

깃플랫폼
git hub, bit bucket, git lab

깃 개념 - 사진참고(page 35)
(혼자)
git add는 트래킹만함 staging area에 잠시 저장만 됨. (커밋전에 임시 저장사항)
이거를 이제 레파에 올려도 되겠네 하면 git commit을 함.
이게 이제 local 레파에 저장됨.

W.D. 폴더보면 .git폴더에 변경사항이 다 저장되는데 

local 레파에서 깃헙(remote repository)로 변경사항을 밀어버리는데 이게 git push. 
local레파로 깃헙에서 끌어올때 이게 git pull.

(여러명)
각자 local레파를 갖고 있음. - 사진참고(page 36)

local 레파에서 작업한 내용은 commit/push를 통해 origin 레파로 업로드.
어느정도 쌓이면 


깃 용어 - 사진참고(page 37)

깃 브랜칭 전략
:여러 분석가가 동시에 작업하면서 동시에 변경사항을 추가할때 저장소를 체계적으로 유지하는 데 도움이 되므로 꼭 필요함.
일과 프로젝트의 규모에 맞는 브랜칭 전략이 필요함.
특히 ML 파이프라인 개발은 일반적인 소프트웨어 개발에서 사용하는 브랜칭 전략이 비효율적일 수 있음.

기본전략 - git flow - 사진참고 (page40)
master : 최종 코드만 관리
develop : 개발한 내용을 관리하는 보조 브래닟
feature : 각 기능을 개발하는 브랜치 (서로 독립적) (종속적이랄면 feature내의 feature가 있고 이럴 수 있음)

feature에서 쓸만하네 develop으로 이동. develop에서 괜찮네 하면 master로 이동
중간 배포해볼까? develop - release로 

요즘 제안하는거
featuer2 feature1 develop master
이런식으로 3가지만 하는거 추천..
ex)모델 두개라서 각자 feature 1,2 이고 모델 개발되면 develop으로 이동. 그리고 최종 채택되면 master가는식으로 진행함.

모든 코드는 merge전에 코드 리뷰과정을 진행하고 merge하는 게 좋음.

git 작업 흐름 - 사진참고 (page 42)

git헙 실습

1)레파 파면 remote repo만든것.
2) 그럼 클론해야겠지? (wd만들기)

git config --global user.name "Yejun Hwang"
git config --global user.email "hwangyj9@gmail.com"
git clone https://github.com/ie-jun/test-repo.git

cd test-repo/


ls -al ( 파일 기본으로 두개 뜸)

echo 'print("hello, world!")' >> hello_world.py  (파일 만드는거)

git status (현재 hello_world.py가 트래킹 안되고있다 알려줄거임  ;   add 해줘야겠지)

git add hello_world.py

git commit -m "Hello, world" (깃은 항상 메세지가 필요함)


확인해볼까?
git log --graph --oneline   (나갈 떄 q)

현재까지 remote repo에 점섬으로 올려놓은거임. 실선으로 바꾸려면 push해줘야겠지

깃헙 설정 들어가서 settings에서 개인 토큰 파기 (beta로 ; permission은 다 맨 아래 read-write)
그리고 주는 토큰은 끄면 못보니 복붙해놓기 (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)

자 이제 push해보자
git push origin main
token에 개인 토큰 입력하면 해당 레포에 푸시됨

다 됐으면 기존 레파로 돌아가서 확인해보면 push된것을 확인 가능

이제 협업할 때 쓸 수 있는 pull request를 해보자.
남 깃헙 들어가서 fork하자.

그다음 다시 git clone하자 (아까 레파에서 가져온것처럼 코드 들어가서 복붙 ; 내 아이디 되어있을 거임)
cd .. (기본 root폴더로 이동한것)
git clone https://github.com/ie-jun/hpo-using-optuna-mlflow.git
하면 다 만들어져 있음.

원하는 내용 만들어서 push 해보자
cd {원하는폴더}
git add {MODIFIED_FILE_NAME}
git commit -m "Hello, world"
git push origin main

(내가해보기)
cd hpo-using-optuna-mlflow/
echo 'print("hello, I'm new recruit")' >> hello_cns.py 
git add hello_cns.py
git commit -m "Hello, cns"
git push origin main

New pull request하기
내꺼 바꾼 후(앞서 했지) New pull request로 어떤 곳에 create pull request하겠다.(강사님 fork한 레포)
원래 갖고 있던 사람은 merge request에 대해 confirm merge해주면 받아들여짐.
그다음에 원래 fork한 레파로 가서 sink맞춰주면 기존 레파에 맞춰 싱크로됨 (오류 뜨면 다 yes누르셈)


------------------------
M3 

머신러닝 파이프라인 정의
정의하는 주체마다 다르지만, 데이터 추출, 데이터 전처리, 모델학습, 모델 배포로 이어지는 모든 순서를 체계화하는 인프라로 설명함

기존 업무 방식과 ML 파이프라인 방식의 차이 

기존 업무 방식
:모델 개발/학습에 목적을 둔 경우가 많음
학습한 모델이 최종 산출물이 됨
작업 중간 단계에서 변경이 발생한 경우, 추적이 어려워 메뉴얼한 작업이 늘어날 수 있음( 주피터 노트북 json기반이라 뭐 저장, plot등등 다 저장되버려서 추적 어렵거든)

ML파이프라인 방식 - 사진참고 (page 6)
:사진 자체가 ML 파이프라인이고.. 이거를 자동화하는 과정이 MLOps임..

ML 파이프라인 환경구성
파이프라인 개발할때는 환경이 되게 중요함. -사진참고(page 8)
개발 서버 , QA서버, 운영 서버 3개가 나뉨

모델 기똥차게 개발하고 이제 운영서버에 갈때, 어떤 패키지 어떤 버전 썼지,,?
이를 잘 처리하기 위해 개발서버- QA서버- 운영서버 순서로 이동할 때 잘 묶어서 일관성 있게 관리해야해
->간단히 동일 환경 유지하려고

파이썬 환경과 패키지 관리 - 사진참고 (page 9)
전역환경 / 가상 환경
분류 모델과 추천알고리즘을 하나의 서버에서 개발할때 각자 numpy 버전이다르다?
분류 모델 패키지와 추천 알고리즘 패키지를 모두 전역환경에 설치하면 버전 충돌 일어나..

예를 들어 scikit-learn 패키지도 설치시 의존성 충돌을 방지하기 위해 독립된 가상환경 사용을 적극 권장함

가상 환경 관리 도구 - 사진참고 (page 11)
venv, virtualenv, pipenv, conda 등등
(기본으로 주는게 많아 무거운 conda 대신 pyenv쓰긴함 얘는 다중 파이썬 제공해주거든)
(추가로 라이브로리 의존성을 위해 pipenve하면 끝)
가상 환경 관리 도구 - Best Practice - 사진참고(page 12)
pipenv로 각 프로젝트를 생성해서 관리 (Pipfile ; 파일 하나당 가상환경 1개)
pyenv로 필요한 다중 파이썬 설치하고..



요즘은 poetry/PDM 씀 (강사님은 PDM 쓰심)
얘네 둘은 버전을 지정하지 않아도 알아서 지정해줌(pipfile은 그게 지원이 안돼)


파이프라인 기초잡기
ML 프로젝트 구조화 & 모듈화 &

ML 프로젝트 구조화
:잘 정의한 표준 프로젝트 구조는 프로젝트 이해 및 부넉에 도움을 주고 수정해야할 기능의 위치를 쉽게 파악할 수 있음

데이터 분석 프로젝트에서도 표준 프로젝트 구조를 정의할 수 있음 - 사진참고 (page 16)
->자동화 툴 있음 Cookiecutter. -사진 page 17에 왼쪽 보면 이거 너무 디테일해서 page 17 오른쪽 처럼 커스터마이징함.

ML 프로젝트 모듈화
:함수,변수 또는 클래스를 모아 놓은 파일을 의미함.
이렇게 프로그램의 기능을 독립적인 파일로 분리하는 작업을 모듈화라고함 -사진참고 (page 18)
how?
ml모델경우 모델 알고리즘 종류 별로 분리
각각 파일은 포함하고 있는 함수,변수,클래스 특성을 잘 반영할 수 있도록 명명함.
파일 내 각각 함수,변수,클래스는 최소 기능별로 분리하여 작성(리팩토링) ; 동일 기능이 여러번 쓰이면 하나의 함수,변수로 추출하는 방식 권장. (정규화를 곳곳에서 쓴다거나)

모듈화 하는 이유?
철저하게 코드의 재활용과 수월한 유지보수를 위해서 해야함. (지속적 ML모델을 운영시스템으로 이관하여 "지속적으로 유지보수"해야 하는 상황에선 필수임)

이렇게 하면 기능을 서로 다른 폴더에 세분화 한 만큼 test코드 작성이 중요해짐..

테스트 개요
크게 3가지 존재함(단위 테스트, 통합테스트, e2e테스트)
단위테스트는 CI에 자동화 되어있는 경우가 많음
Codium AI에서 단위테스트 자동으로 코드 짜준다 (gpt기반이겠지)

ML시스템 테스트가 소프트웨어 개발 테스트와 다른점
:ML시스템은 사전에 명확하게 지정할 수 없는 데이터와 모델에 따라 크게 달라짐. 사진참고(page22)

ML시스템 테스트
데이터 테스트, 모델 테스트, ML인프라테스트, 모니터리 테스트 - 세부사항 사진참고(page23)

ML프로젝트 로그관리 - 로그의 중요성
:DEBUT, INFO, WARN, ERROR 

ML 프로젝트 로그관리 - python 로그 모듈 구성요소
사진참고 (page26) LOGGER 내부에 Filter 내부에 Formatter 구성됨.
!!로그 예시 - 사진참고(page27)

--------
ML 파이프라인 개발 도구
:ML엔지니어링 주요 업무는 모델이 운영될 환경에 가장 적합한 ML 파이프라인을 설계/구현 하는일 - 사진참고(page29)
각 도구마다 활용 시나리오와 장단점이 서로 다름.

강사님은 mlflow , bento-ML 순서대로 많이 쓰심

데이터 버저닝 - DAGsHub , DVC (우리는 쓸 일 거의 없음)
ML프로젝트에서 재현성 보장을 위해 모델의 버전을 기록하는 것처럼 데이터의 버전을 기록
피처를 업데이트하거나 데이터의 메타 정보가 바뀌었을 때 해당 데이터의 메타 데이터, 데이터 내용 드을 버저닝


Feature Store
:ML 모델 학습을 위해 사용하는 피처를 저장하는 중앙화된 저장소
ML 모델에 사용할 피처만 저장하고 오프라인과 온라인 피처를 모두 관리함.
주기적으로 온라인 피처를 오프라인 저장소에 넘겨줌(backfill)
실시간 데이터에 대해 엔저니어링한 피처를 제공하여 low latency를 유지할 수있음.
(우린 잘 안쓴대)

모델 실험 관리
:학습한 ML모델의 산출물인 모델 아티팩트를 관리하고 모델 실험 결과를 관리함.
모델 아티팩트(다양한 메타데이터와 모델 파일, 평가 메트릭, 모델 버전 등을 포함)
ML파이프라인 구성 요소중 DS에 가장 익숙
모델 실험 관리가 가능한 도구는 대부분 모델 배포/서빙 기능 까지 포함(제일 좋은애 배포/서빙할거잖아)

모델 배포/서빙(Bento ML 추천)
:배포는 ML모델을 운영 서버에 올리는 모든 행동을 포함하며
서빙은 배포 전략중 하나로 최종 사용자에게 엔드포인트 등을 통해 결과를 제공하는 것.

모델 모니터링유지보수(Deepchecks추천)
:일반적인 리소스 모니터링과 구분하기 위해 최근 모델 Observability라고 부름.
리소스 모니터링 도구는 보통 Grafana와 Promeheus사용함.
리소스 모니터링 도구는 ML 파이프라인과 관련 없이 서버 올라가면 사용하니까 운영환경에서 필수적임(이 강의에선 안이룸)
prediction drift가 어떻네 boosting overfit됐네 뭐시기 다나옴
train과 test데이터의 정답 분포가 다른 걸 확인해준다거나..




파이프라인 오케스트레이션 tool(Kubeflow 설치 까다로움 ; 보통 클라우드에 설치함 ; 로컬에 설치 힘듬(윈도우 안됨) ;)
(우리는 airflow를 쓰는게 맞음)
:간단한 인터페이스로 워크플로우와 파이프라인 인프라를 관리함.


ML파이프라인 구축에 상황에 맞는 적절한 도구사용이 중요함 - 사진참조(page38)
Ray 추천.
Ray 이해를 위한 설명)
Python - Multi-Processing.
4개의 코어가 있다면 Multi processing쓴다면 4배 빨라져야함. 근데 실제 써보면 2배는 빨라지나?
일을 4개 코어에 분배해주는게 가장 좋은데.. 통신을 하면서 통신해야하는데 파이썬은 이 통신이 무거워 메모리를 쳐먹어버려.(pickle을 직렬화해서 왔다갔따해버림)
RAY는 이러한 통신방식을 바꿨음.. 4개코어면 3배정도까진 끌어올렸어 ->Ray Tune 통해 모델실험관리에 쓰임.
주의사항은 

프로젝트 시나리오 유형별 제안- 사진참고(page39)
ML 모델 실험 수행 & ML 모델을 배포/서빙할 때 까지정도만 일단 익혀놔도 될듯.

------
MLflow (모델실험관리도구)직접 써보기

실습파일 실행 가능(주피터파일이라 코랩들어가서 노트업로드?)
로그처리 mlflow.sklearn.autolog()하면 웬마한거 다 해주는데 실습에선 사용하지 말자.(태그든 파라미터든 로그로 남기면됨)

----
전체 요약
MLOps
CI:지속적 통합
CD:지속적 제공

CNS MLOps 표준 도식화 - 그림참조(page 47)
